tmp2 = tmp2[order(tmp2)]
tmp1[1]
tmp2[1]
plot(tmp1,tmp2)
sum(tmp1==tmp2)
mean(tmp1==tmp2)
tmp1 = pvalueData3[,3]#
tmp2 = pvalueData[,3]
tmp1[1]
tmp1 = as.numeric(tmp1)
colnames(pvalueData3)
pvals1 = as.numeric(pvalueData3[,1])
pvals2 = as.numeric(pvalueData[,1])
pvals1[1]
pvals2[1]
pvals1 = pvals1[order(tmp1)]
pvals2 = pvals1[order(tmp2)]
sum(pvals1==pvals2)
length(pvals1)
ne = which(pvals1!=pvals2)
ne[1]
pvals1 = as.numeric(pvalueData3[,1])
pvals2 = as.numeric(pvalueData[,1])
pvals1 = pvals1[order(tmp1)]
pvals2 = pvals2[order(tmp2)]
sum(pvals1==pvals2)
length(pvals1)
mean(pvals1==pvals2)
mean((pvals1 - pvals2) < 1e-3)
mean((pvals1 - pvals2) < 1e-5)
mean(abs(pvals1 - pvals2) < 1e-5 )
dim(pvalueData)
dim(pvalueData3)
rm(list=ls())
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
dim(pvalueData)
rm(list=ls())
pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueData.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueData.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
tmpData
i
j
tmpData = getAbstractsPmids(journals[i],years[j])
while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
barplot(c(1,1,-3))
?barplot
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12[1,]
pres08 = read.csv("~/Desktop/2008pres.csv")
pres08[1,]
sum(pres12$FIPS == 0)
table(pres12$X[pres12$FIPS==0,])
table(pres12$X[pres12$FIPS==0])
pres12[pres12$X=="OK",]
pres12 = pres12[pres12$FIPS==0,]
dim(pres12)
pres12[1,]
pres12[2,]
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12[1:10,]
pres12[21:30,]
pres12[50:100,]
pres12 = pres12[pres12$FIPS==0,]
length(unique(pres12$X))
which.max(pres12$X == "OK")
which(pres12$X == "OK")
pres12[c(36,37)]
pres12[c(36,37),]
pres12[1,]
pres12[1,5]
pres12[1,4]
as.numeric(pres12[1,4])
as.numeric(as.character(pres12[1,4])
)
as.numeric(as.character(pres12[1,4]))
pres08[1,]
sum(pres08$LAST.NAME == "McCain")
sum(pres08$LAST.NAME == "McCain" & pres08$STATE=="Alabama")
pres08[pres08$LAST.NAME == "McCain",]
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
pres12[1,]
table(unique(pres12))
table(unique(pres12$x))
table(unique(pres12$X))
substr
gsub
gsub(pres12[1,3])
pres12[1,]
pres12$Obama.vote[1]
dem12 = as.character(pres12$Obama.vote)
dem12[1]
dem12 = sapply(dem12,function(x){gsub(x,",","")})
dem12[1]
dem12 = as.character(pres12$Obama.vote)
gsub(dem12[1],",","")
?gsub
gsub(",","",dem12[1])
dem12 = as.character(pres12$Obama.vote)
dem12 = as.numeric(sapply(dem12,function(x){gsub(",","",x)}))
dem12[1]
hist(dem12)
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
dem12 = as.character(pres12$Obama.vote)
dem12 = as.numeric(sapply(dem12,function(x){gsub(",","",x)}))
rep12 = as.character(pres12$Romney.vote)
rep12 = as.numeric(sapply(rep12,function(x){gsub(",","",x)}))
plot(rep12,dem12)
rep12[1]
pres12[1,]
table(pres12[,2])
res12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
table(pres12[,2])
table(pres12[,1])
library(XML)
theurl <- "http://uselectionatlas.org/RESULTS/data.php?year=2008&datatype=national&def=1&f=0&off=0&elect=0"
tables <- readHTMLTable(theurl)
tables[1,]
dim(tables)
tables[1]
tables
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
n.rows
library(slidify)
?author
setwd("~/Documents/Work/teaching/2013/coursera/")
ls()
list.files()
author("gettingStarted")
slidify("gettingStarted")
ls()
list.files()
slidify("index.Rmd")
setwd("~/Documents/Work/teaching/2013/coursera/")
setwd("gettingHelp/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
getwd()
setwd("../aboutDataAnalysis/")
slidify("index.Rmd")
setwd("~/Dropbox/Jeff/teaching/2013/")
setwd("753/lectures/")
setwd("001courseMotivation/")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Dropbox/Jeff/teaching/2013/753/jhsph753/lectures/001courseMotivation/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Dropbox/Jeff/teaching/2013/753/jhsph753/intros/003intro/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Documents/Work/code/github/swfdr/")
load("pvalueData.rda")cNames = colnames(pvalueData)[1:4]rNames = rownames(pvalueData)pvalueData = matrix(as.numeric(pvalueData[,1:4]),ncol=4)colnames(pvalueData) = cNamesrownames(pvalueData) = rNamessource("calculateSwfdr.R")source("journalAnalysisHelp.R")library(stats4)library(genefilter)library(lme4)
Initialize the variablespercent05 = pi0JournalYear = matrix(NA,nrow=5,ncol=11)pi0Journal = rep(NA,5)# Get the journals and yearsjournals = unique(rownames(pvalueData))years = unique(pvalueData[,4])# Get the percent of P-values less than 0.05 by journal/yearfor(i in 1:length(journals)){  for(j in 1:length(years)){    percent05[i,j] = mean(as.numeric(pvalueData[pvalueData[,4]==years[j] & rownames(pvalueData) == journals[i],1]) < 0.05,na.rm=T)  }}
Estimated the swfdr by journal/yearfor(i in 1:length(journals)){  for(j in 1:length(years)){    tmp = pvalueData[pvalueData[,4]==years[j] & rownames(pvalueData) == journals[i] & pvalueData[,1] < 0.05,]    tt = tmp[,2]    rr = rep(0,length(tt))    rr[tt == 0] = (tmp[tt==0,1] == round(tmp[tt==0,1],2))    pp = tmp[,1]    out = calculateSwfdr(pValues = pp, truncated = tt, rounded = rr, numEmIterations=100)    pi0JournalYear[i,j] = out$pi0    cat(j)  }  cat(i)  cat("\n")}
numSubmissions = matrix(NA,nrow=length(journals),ncol=11)rownames(numSubmissions) = journalsnumSubmissions[2,] = c(4366, 4189, 4615, 5064, 5184, 5744, 5352, 5551, 5525, 5946, 5878)numSubmissions[3,] = c(3566,3758,4238,4486,4870,5066,5037,5412,5909,5642,5284)numSubmissions[5,] = c(649,609,652,705,817,970,947,922,1010,985,1030)numSubmissions[4,] = c(NA,NA,NA,3477,3738,4051,3398,3207,3361,3792,3486)numSubmissions[1,] = c(NA,NA,NA,NA,NA,NA,5254,4770,4720,4609,4612)
journalInd = as.factor(rep(1:5,each=11))yearsVals = rep(2000:2010,5)numSubVec = as.vector(t(numSubmissions))pi0JournalYearVec = as.vector(t(pi0JournalYear))
lm1 <- lm(pi0JournalYearVec ~as.factor(journalInd)*yearsVals)anova(lm1)
lm1 <- lm(pi0JournalYearVec ~as.factor(journalInd)*yearsVals)summary(lm1)
lm2 <- lm(pi0JournalYearVec ~ as.factor(journalInd)*numSubVec)summary(lm2)
lm2 <- lm(pi0JournalYearVec ~ as.factor(journalInd) + numSubVec)summary(lm2)
lm2 <- lm(pi0JournalYearVec ~ as.factor(journalInd) + numSubVec)summary(lm2)
lm2 <- lm(pi0JournalYearVec ~ as.factor(journalInd) * numSubVec)summary(lm2)
3.6*3
par(mfcol=c(5,3),mar=3*c(2,3,1,1))for(i in 1:3){  for(j in 1:length(journals)){    hist(pvalueData[pvalueData[,4]== years3[i] & rownames(pvalueData)==journals[j] & pvalueData[,1] < 0.05,1],breaks=50,freq=F,xlab="",ylab="",xlim=c(0,0.05),main="",col=cols[j],ylim=c(0,600),border="black",cex.axis=2)    text(0.025,400,paste(journalAbb[j],years3[i]),cex=5)    mtext("p-value",side=1,line=3,cex=2)    mtext("Density",side=2,line=3,cex=2)  }}
years3 = c(2000,2005,2010)
par(mfcol=c(5,3),mar=3*c(2,3,1,1))for(i in 1:3){  for(j in 1:length(journals)){    hist(pvalueData[pvalueData[,4]== years3[i] & rownames(pvalueData)==journals[j] & pvalueData[,1] < 0.05,1],breaks=50,freq=F,xlab="",ylab="",xlim=c(0,0.05),main="",col=cols[j],ylim=c(0,600),border="black",cex.axis=2)    text(0.025,400,paste(journalAbb[j],years3[i]),cex=5)    mtext("p-value",side=1,line=3,cex=2)    mtext("Density",side=2,line=3,cex=2)  }}
cols = c("blue","red","orange","green","purple","darkgrey")journalAbb =c("Lancet","JAMA","NEJM","BMJ","AJE")
par(mfcol=c(5,3),mar=3*c(2,3,1,1))for(i in 1:3){  for(j in 1:length(journals)){    hist(pvalueData[pvalueData[,4]== years3[i] & rownames(pvalueData)==journals[j] & pvalueData[,1] < 0.05,1],breaks=50,freq=F,xlab="",ylab="",xlim=c(0,0.05),main="",col=cols[j],ylim=c(0,600),border="black",cex.axis=2)    text(0.025,400,paste(journalAbb[j],years3[i]),cex=5)    mtext("p-value",side=1,line=3,cex=2)    mtext("Density",side=2,line=3,cex=2)  }}
pdf("figure3.pdf",height=5*8,width=3*8)par(mfcol=c(5,3),mar=3*c(2,3,1,1))for(i in 1:3){  for(j in 1:length(journals)){    hist(pvalueData[pvalueData[,4]== years3[i] & rownames(pvalueData)==journals[j] & pvalueData[,1] < 0.05,1],breaks=50,freq=F,xlab="",ylab="",xlim=c(0,0.05),main="",col=cols[j],ylim=c(0,600),border="black",cex.axis=2)    text(0.025,400,paste(journalAbb[j],years3[i]),cex=5)    mtext("p-value",side=1,line=3,cex=2)    mtext("Density",side=2,line=3,cex=2)  }}dev.off()
lm1 <- lm(pi0JournalYearVec ~as.factor(journalInd) + yearsVals)summary(lm1)
confint(lm1)
summary(lm2)
lm2 <- lm(pi0JournalYearVec ~ as.factor(journalInd) + numSubVec)summary(lm2)
100*4.153e-05
